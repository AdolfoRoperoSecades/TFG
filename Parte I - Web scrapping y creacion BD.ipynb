{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Comenzamos importando las librerías que usaremos\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import sqlite3\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.express as px\n"
      ],
      "metadata": {
        "id": "_p-SWmD9HcB-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web scraping y creación de la base de datos"
      ],
      "metadata": {
        "id": "HA6qAJ1SG4jN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado obtenemos los poemas usando web scraping en la página web www.poesi.as. Creamos un base SQL para guardar la información obtenida en una tabla con la siguiente estructura: [autor - título - poema]"
      ],
      "metadata": {
        "id": "ig4h1Fd0HgFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un diccionario con el nombre de los autores y sus identificadores en la página web objetivo\n",
        "dict_autores = {\n",
        "    'Pedro_Salinas.htm': 'ps',\n",
        "    'Jorge_Guillen.htm': 'jg',\n",
        "    'Vicente_Aleixandre.htm': 'va',\n",
        "    'Gerardo_Diego.htm': 'gd',\n",
        "    'Federico_Garcia_Lorca.htm': 'fgl',\n",
        "    'Emilio_Prados.htm': 'ep',\n",
        "    'Damaso_Alonso.htm': 'da',\n",
        "    'Rafael_Alberti.htm': 'ra',\n",
        "    'Luis_Cernuda.htm': 'lc',\n",
        "    'Manuel_Altolaguirre.htm': 'al'\n",
        "}\n",
        "\n",
        "# Especficamos la URL base\n",
        "base_url = 'https://www.poesi.as/'\n",
        "\n",
        "# Creamos una base de datos SQLite3\n",
        "conn = sqlite3.connect('poemas.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Creamos una tabla para almacenar el contenido de los poemas\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS poemas\n",
        "                  (autor TEXT, titulo TEXT, poema TEXT)''')\n",
        "\n",
        "# Recorremos el diccionario de autores y hacemos la solicitud HTTP\n",
        "for autor, identificador in dict_autores.items():\n",
        "    url_autor = base_url + autor\n",
        "    response = requests.get(url_autor)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    poem_counter = 0  # Contador para limitar a 100 poemas por autor\n",
        "\n",
        "    for p_tag in soup.find_all('p', class_=['p1', 'p2', 'p3', 'p4']):\n",
        "        if poem_counter >= 100:  # Si ya hemos extraído al menos 100 poemas, paramos el bucle\n",
        "            break\n",
        "\n",
        "        link_tag = p_tag.find('a')\n",
        "        if link_tag and 'href' in link_tag.attrs:\n",
        "            direccion_web = base_url + link_tag['href']\n",
        "\n",
        "            # Hacemos una solicitud a la dirección web del poema\n",
        "            response_poema = requests.get(direccion_web)\n",
        "            soup_poema = BeautifulSoup(response_poema.content, 'html.parser')\n",
        "\n",
        "            # Extraemos el título del poema\n",
        "            titulo = link_tag.text.lower()\n",
        "\n",
        "            # Extraemos el contenido del poema sin etiquetas <p> dentro de <div class=\"poema\">\n",
        "            contenido_poema = ''.join([p.text.strip() for p in soup_poema.select('div.poema p:not([class])')])\n",
        "\n",
        "            # Realizamos las modificaciones en el texto del poema, para evitar errores de formato en los saltos de línea vacia en los poemas resultantes\n",
        "            contenido_poema = contenido_poema.replace('\\r\\n', '\\n')\n",
        "\n",
        "            # Insertamos en la base de datos el título, el nombre del autor, el contenido del poema\n",
        "            cursor.execute(\"INSERT INTO poemas (autor, titulo, poema) VALUES (?, ?, ?)\",\n",
        "                           (autor.lower().replace('_', ' ').replace('.htm', ''), titulo, contenido_poema.strip()))\n",
        "\n",
        "            poem_counter += 1  # Incrementar el contador de poemas extraídos por autor\n",
        "\n",
        "# Llevamos a cabo los cambios en la base de datos con Commit y cerramos la conexión\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Extracción y almacenamiento completados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfCe2Y3AG3RY",
        "outputId": "10270a41-f90b-47c0-d7c7-bd077e06a0e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracción y almacenamiento completados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos que obtenemos 100 poemas para cada autor\n",
        "# Comenzamos conectando a la base de datos poemas.db\n",
        "conn_db1 = sqlite3.connect('poemas.db')\n",
        "cursor_db1 = conn_db1.cursor()\n",
        "\n",
        "# Calculamos el conteo de poemas para cada autor por medio de una función de agregación\n",
        "cursor_db1.execute(\"SELECT autor, COUNT(*) FROM poemas GROUP BY autor\")\n",
        "conteo_poemas_db1 = cursor_db1.fetchall()\n",
        "\n",
        "# Mostramos el conteo de poemas por autor\n",
        "for autor, cantidad_poemas in conteo_poemas_db1:\n",
        "    print(f\"Autor: {autor}, Poemas: {cantidad_poemas}\")\n",
        "\n",
        "# Cerramos conexión a la primera base de datos\n",
        "conn_db1.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRhm_P4VLx9m",
        "outputId": "c9d7617e-c4ed-4ace-f663-e195f54df365"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autor: damaso alonso, Poemas: 66\n",
            "Autor: emilio prados, Poemas: 62\n",
            "Autor: federico garcia lorca, Poemas: 100\n",
            "Autor: gerardo diego, Poemas: 100\n",
            "Autor: jorge guillen, Poemas: 100\n",
            "Autor: luis cernuda, Poemas: 100\n",
            "Autor: manuel altolaguirre, Poemas: 100\n",
            "Autor: pedro salinas, Poemas: 100\n",
            "Autor: rafael alberti, Poemas: 95\n",
            "Autor: vicente aleixandre, Poemas: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportar la base de datos a csv"
      ],
      "metadata": {
        "id": "xlmkprS_IiC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la conexión a la base de datos que hemos creado en el paso anterior\n",
        "conn = sqlite3.connect('poemas.db')\n",
        "\n",
        "# Consultamos todos los datos de la tabla por medio del comando SELECT *\n",
        "query = 'SELECT * FROM poemas'\n",
        "\n",
        "# Creamos el dataframe con la información de la consulta a la base de datos\n",
        "df = pd.read_sql_query(query, conn)\n",
        "\n",
        "# Cerramos la conexión a la base de datos\n",
        "conn.close()\n",
        "\n",
        "# Exportamos el DataFrame a un archivo CSV en Google Drive con el nombre db.csv\n",
        "df.to_csv(\"/content/db.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "5trFrWv3IeNB"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}